{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from lib.feature_selection import feature_reduction\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "npf = pd.read_csv(\"data/npf_train.csv\")\n",
    "npf.iloc[:,5:]\n",
    "\n",
    "data = feature_reduction(npf)\n",
    "X = data.iloc[:,2:]\n",
    "y2 = data['class2']\n",
    "y4 = data['class4']\n",
    "X_norm = (X - X.min())/(X.max()-X.min())\n",
    "X_all = npf.iloc[:,5:]\n",
    "\n",
    "# define dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_norm, y2, stratify = y2,test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.870538 using {'C': 100, 'penalty': 'l2', 'solver': 'sag'}\n",
      "0.864050 (0.060183) with: {'C': 100, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.864050 (0.060183) with: {'C': 100, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.864050 (0.060183) with: {'C': 100, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.870538 (0.055204) with: {'C': 100, 'penalty': 'l2', 'solver': 'sag'}\n",
      "0.869427 (0.054256) with: {'C': 100, 'penalty': 'l2', 'solver': 'saga'}\n",
      "0.860681 (0.059690) with: {'C': 10, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.860681 (0.059690) with: {'C': 10, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.861792 (0.059480) with: {'C': 10, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.858530 (0.059861) with: {'C': 10, 'penalty': 'l2', 'solver': 'sag'}\n",
      "0.859642 (0.059692) with: {'C': 10, 'penalty': 'l2', 'solver': 'saga'}\n",
      "0.857276 (0.052943) with: {'C': 1.0, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.857276 (0.052943) with: {'C': 1.0, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.857276 (0.052943) with: {'C': 1.0, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.857276 (0.052943) with: {'C': 1.0, 'penalty': 'l2', 'solver': 'sag'}\n",
      "0.857276 (0.052943) with: {'C': 1.0, 'penalty': 'l2', 'solver': 'saga'}\n",
      "0.815806 (0.054257) with: {'C': 0.1, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.815806 (0.054257) with: {'C': 0.1, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.821290 (0.054893) with: {'C': 0.1, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.815806 (0.054257) with: {'C': 0.1, 'penalty': 'l2', 'solver': 'sag'}\n",
      "0.815806 (0.054257) with: {'C': 0.1, 'penalty': 'l2', 'solver': 'saga'}\n",
      "0.789785 (0.066984) with: {'C': 0.01, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.789785 (0.066984) with: {'C': 0.01, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.791111 (0.063923) with: {'C': 0.01, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.789785 (0.066984) with: {'C': 0.01, 'penalty': 'l2', 'solver': 'sag'}\n",
      "0.789785 (0.066984) with: {'C': 0.01, 'penalty': 'l2', 'solver': 'saga'}\n",
      "0.783297 (0.065155) with: {'C': 0.001, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.783297 (0.065155) with: {'C': 0.001, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.743154 (0.068754) with: {'C': 0.001, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.783297 (0.065155) with: {'C': 0.001, 'penalty': 'l2', 'solver': 'sag'}\n",
      "0.783297 (0.065155) with: {'C': 0.001, 'penalty': 'l2', 'solver': 'saga'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Software\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# define models and parameters\n",
    "model = LogisticRegression()\n",
    "solvers = ['newton-cg', 'lbfgs', 'liblinear','sag','saga']\n",
    "penalty = ['l2']\n",
    "c_values = [100, 10, 1.0, 0.1, 0.01,0.001]\n",
    "# define grid search\n",
    "grid = dict(solver=solvers,penalty=penalty,C=c_values)\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)\n",
    "grid_result = grid_search.fit(X_train, y_train)\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8223684210526315"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "clf =LogisticRegression(C=100,penalty='l2',solver='sag',random_state=1,max_iter=1000).fit(X_train, y_train)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(clf.predict(X_test),y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.643871 using {'C': 1.0, 'penalty': 'l1', 'solver': 'saga'}\n",
      "0.610179 (0.079188) with: {'C': 100, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.592652 (0.074000) with: {'C': 100, 'penalty': 'l1', 'solver': 'saga'}\n",
      "0.609068 (0.065555) with: {'C': 10, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.611111 (0.070406) with: {'C': 10, 'penalty': 'l1', 'solver': 'saga'}\n",
      "0.629642 (0.053354) with: {'C': 1.0, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.643871 (0.047035) with: {'C': 1.0, 'penalty': 'l1', 'solver': 'saga'}\n",
      "0.591577 (0.044042) with: {'C': 0.1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.573118 (0.041230) with: {'C': 0.1, 'penalty': 'l1', 'solver': 'saga'}\n",
      "0.254839 (0.011257) with: {'C': 0.01, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.500323 (0.022121) with: {'C': 0.01, 'penalty': 'l1', 'solver': 'saga'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Software\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_norm, y4, stratify = y4,test_size=0.33, random_state=42)\n",
    "\n",
    "# define models and parameters\n",
    "model = LogisticRegression()\n",
    "solvers = ['liblinear','saga']\n",
    "penalty = ['l1']\n",
    "c_values = [100, 10, 1.0, 0.1, 0.01]\n",
    "# define grid search\n",
    "grid = dict(solver=solvers,penalty=penalty,C=c_values)\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)\n",
    "grid_result = grid_search.fit(X_train, y_train)\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.590502 using {'C': 10, 'penalty': 'none', 'solver': 'saga'}\n",
      "0.571111 (0.085374) with: {'C': 100, 'penalty': 'none', 'solver': 'newton-cg'}\n",
      "0.581971 (0.067817) with: {'C': 100, 'penalty': 'none', 'solver': 'lbfgs'}\n",
      "0.585233 (0.063554) with: {'C': 100, 'penalty': 'none', 'solver': 'sag'}\n",
      "0.589427 (0.075669) with: {'C': 100, 'penalty': 'none', 'solver': 'saga'}\n",
      "0.571111 (0.085374) with: {'C': 10, 'penalty': 'none', 'solver': 'newton-cg'}\n",
      "0.581971 (0.067817) with: {'C': 10, 'penalty': 'none', 'solver': 'lbfgs'}\n",
      "0.584158 (0.066137) with: {'C': 10, 'penalty': 'none', 'solver': 'sag'}\n",
      "0.590502 (0.075766) with: {'C': 10, 'penalty': 'none', 'solver': 'saga'}\n",
      "0.571111 (0.085374) with: {'C': 1.0, 'penalty': 'none', 'solver': 'newton-cg'}\n",
      "0.581971 (0.067817) with: {'C': 1.0, 'penalty': 'none', 'solver': 'lbfgs'}\n",
      "0.588530 (0.065921) with: {'C': 1.0, 'penalty': 'none', 'solver': 'sag'}\n",
      "0.590502 (0.075766) with: {'C': 1.0, 'penalty': 'none', 'solver': 'saga'}\n",
      "0.571111 (0.085374) with: {'C': 0.1, 'penalty': 'none', 'solver': 'newton-cg'}\n",
      "0.581971 (0.067817) with: {'C': 0.1, 'penalty': 'none', 'solver': 'lbfgs'}\n",
      "0.585269 (0.065020) with: {'C': 0.1, 'penalty': 'none', 'solver': 'sag'}\n",
      "0.588351 (0.075097) with: {'C': 0.1, 'penalty': 'none', 'solver': 'saga'}\n",
      "0.571111 (0.085374) with: {'C': 0.01, 'penalty': 'none', 'solver': 'newton-cg'}\n",
      "0.581971 (0.067817) with: {'C': 0.01, 'penalty': 'none', 'solver': 'lbfgs'}\n",
      "0.586308 (0.065987) with: {'C': 0.01, 'penalty': 'none', 'solver': 'sag'}\n",
      "0.588351 (0.075097) with: {'C': 0.01, 'penalty': 'none', 'solver': 'saga'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Software\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Software\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# define models and parameters\n",
    "model = LogisticRegression()\n",
    "solvers = ['newton-cg', 'lbfgs','sag','saga']\n",
    "penalty = ['none']\n",
    "c_values = [100, 10, 1.0, 0.1, 0.01]\n",
    "# define grid search\n",
    "grid = dict(solver=solvers,penalty=penalty,C=c_values)\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)\n",
    "grid_result = grid_search.fit(X_train, y_train)\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.625305 using {'C': 1.0, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.586201 (0.062897) with: {'C': 100, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.593907 (0.066549) with: {'C': 100, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.587312 (0.072189) with: {'C': 100, 'penalty': 'l2', 'solver': 'sag'}\n",
      "0.592616 (0.065908) with: {'C': 100, 'penalty': 'l2', 'solver': 'saga'}\n",
      "0.612222 (0.068454) with: {'C': 10, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.611183 (0.067511) with: {'C': 10, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.612222 (0.065871) with: {'C': 10, 'penalty': 'l2', 'solver': 'sag'}\n",
      "0.610036 (0.069694) with: {'C': 10, 'penalty': 'l2', 'solver': 'saga'}\n",
      "0.625305 (0.049059) with: {'C': 1.0, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.625305 (0.049059) with: {'C': 1.0, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.625305 (0.049059) with: {'C': 1.0, 'penalty': 'l2', 'solver': 'sag'}\n",
      "0.625305 (0.049059) with: {'C': 1.0, 'penalty': 'l2', 'solver': 'saga'}\n",
      "0.599283 (0.051598) with: {'C': 0.1, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.599283 (0.051598) with: {'C': 0.1, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.599283 (0.051598) with: {'C': 0.1, 'penalty': 'l2', 'solver': 'sag'}\n",
      "0.599283 (0.051598) with: {'C': 0.1, 'penalty': 'l2', 'solver': 'saga'}\n",
      "0.500323 (0.022121) with: {'C': 0.01, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.500323 (0.022121) with: {'C': 0.01, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.500323 (0.022121) with: {'C': 0.01, 'penalty': 'l2', 'solver': 'sag'}\n",
      "0.500323 (0.022121) with: {'C': 0.01, 'penalty': 'l2', 'solver': 'saga'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# define models and parameters\n",
    "model = LogisticRegression()\n",
    "solvers = ['newton-cg', 'lbfgs','sag','saga']\n",
    "penalty = ['l2']\n",
    "c_values = [100, 10, 1.0, 0.1, 0.01]\n",
    "# define grid search\n",
    "grid = dict(solver=solvers,penalty=penalty,C=c_values)\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)\n",
    "grid_result = grid_search.fit(X_train, y_train)\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6513157894736842"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf =LogisticRegression(C=1,penalty='l1',solver='saga',random_state=1,max_iter=1000).fit(X_train, y_train)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(clf.predict(X_test),y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5053848f1e1ce6d9c67b4d0af35009a6322e9959d1af6f676e18003e4a846f54"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
