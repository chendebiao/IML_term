{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "data = pd.read_csv(\"data/38_feature.csv\",index_col=0)\n",
    "data_norm = pd.read_csv(\"data/38_feature_norm.csv\",index_col=0)\n",
    "data_std_scale = pd.read_csv(\"data/38_feature_std_scale.csv\",index_col=0)\n",
    "\n",
    "X = data.iloc[:,2:]\n",
    "y2 = data['class2']\n",
    "y4 = data['class4']\n",
    "X_norm = data_norm.iloc[:,2:]\n",
    "X_std_scale = data_std_scale.iloc[:,2:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_norm, y2, stratify=y2 ,test_size=0.20, random_state=42)\n",
    "\n",
    "# LR\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "LR_clf =LogisticRegression(C=20,penalty='l2',solver='liblinear',random_state=1,max_iter=1000).fit(X_train, y_train)\n",
    "\n",
    "# SVC\n",
    "from sklearn.svm import SVC\n",
    "SVC_clf =SVC(C=1.0,kernel='poly',probability=True).fit(X_train, y_train)\n",
    "\n",
    "# GB\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "GB_clf = GradientBoostingClassifier(n_estimators = 1000,learning_rate=0.01,subsample=0.5,max_depth=7).fit(X_train, y_train)\n",
    "\n",
    "# RF\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "RF_clf = RandomForestClassifier(max_features = 'sqrt',n_estimators=100).fit(X_train, y_train)\n",
    "\n",
    "# softvoting ensemble\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "eclf_2 = VotingClassifier(\n",
    "    estimators=[\\\n",
    "    ('LR', LR_clf),\n",
    "    ('SVC_clf', SVC_clf),\n",
    "    ('RF_clf', RF_clf),\n",
    "    ('GB_clf',GB_clf)], \n",
    "    voting='soft', \n",
    "    weights=[1, 1, 1, 1]).fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4-class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_norm, y4, stratify=y4 ,test_size=0.20, random_state=42)\n",
    "\n",
    "# LR\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "LR_clf =LogisticRegression(C=20,penalty='l2',solver='liblinear',random_state=1,max_iter=1000).fit(X_train, y_train)\n",
    "\n",
    "# RF\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "RF_clf = RandomForestClassifier(max_features = 'sqrt',n_estimators=1000)\n",
    "RF_clf.fit(X_train, y_train)\n",
    "\n",
    "# GB\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "GB_clf = GradientBoostingClassifier(n_estimators = 1000,learning_rate=0.01,subsample=0.7,max_depth=7)\n",
    "GB_clf.fit(X_train, y_train)\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "eclf_4 = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('RF_clf', RF_clf),\n",
    "        ('GB_clf', GB_clf),\n",
    "        ('LR_clf', LR_clf)],\n",
    "    voting='hard').fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test_hidden data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CO2168.mean</th>\n",
       "      <th>CO2168.std</th>\n",
       "      <th>H2O168.mean</th>\n",
       "      <th>H2O168.std</th>\n",
       "      <th>NO168.std</th>\n",
       "      <th>NO336.std</th>\n",
       "      <th>NO42.std</th>\n",
       "      <th>NO504.mean</th>\n",
       "      <th>NO504.std</th>\n",
       "      <th>NO672.std</th>\n",
       "      <th>...</th>\n",
       "      <th>RPAR.mean</th>\n",
       "      <th>RPAR.std</th>\n",
       "      <th>SO2168.mean</th>\n",
       "      <th>SO2168.std</th>\n",
       "      <th>SWS.mean</th>\n",
       "      <th>SWS.std</th>\n",
       "      <th>T84.mean</th>\n",
       "      <th>T84.std</th>\n",
       "      <th>CS.mean</th>\n",
       "      <th>CS.std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.278938</td>\n",
       "      <td>0.018998</td>\n",
       "      <td>0.183163</td>\n",
       "      <td>0.022930</td>\n",
       "      <td>0.009311</td>\n",
       "      <td>0.012234</td>\n",
       "      <td>0.085353</td>\n",
       "      <td>0.011402</td>\n",
       "      <td>0.017434</td>\n",
       "      <td>0.011019</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018861</td>\n",
       "      <td>0.028178</td>\n",
       "      <td>0.022406</td>\n",
       "      <td>0.015538</td>\n",
       "      <td>0.963095</td>\n",
       "      <td>0.003594</td>\n",
       "      <td>0.426378</td>\n",
       "      <td>0.028074</td>\n",
       "      <td>0.025721</td>\n",
       "      <td>0.015359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.504000</td>\n",
       "      <td>0.015784</td>\n",
       "      <td>0.022105</td>\n",
       "      <td>0.007552</td>\n",
       "      <td>0.193844</td>\n",
       "      <td>0.278596</td>\n",
       "      <td>0.125013</td>\n",
       "      <td>0.121995</td>\n",
       "      <td>0.281247</td>\n",
       "      <td>0.279674</td>\n",
       "      <td>...</td>\n",
       "      <td>0.190066</td>\n",
       "      <td>0.239194</td>\n",
       "      <td>0.194391</td>\n",
       "      <td>0.035191</td>\n",
       "      <td>0.941012</td>\n",
       "      <td>0.010179</td>\n",
       "      <td>0.129581</td>\n",
       "      <td>0.087790</td>\n",
       "      <td>0.222128</td>\n",
       "      <td>0.014814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.257581</td>\n",
       "      <td>0.050786</td>\n",
       "      <td>0.193513</td>\n",
       "      <td>0.136942</td>\n",
       "      <td>0.020796</td>\n",
       "      <td>0.030065</td>\n",
       "      <td>0.009843</td>\n",
       "      <td>0.010364</td>\n",
       "      <td>0.025180</td>\n",
       "      <td>0.028995</td>\n",
       "      <td>...</td>\n",
       "      <td>0.159068</td>\n",
       "      <td>0.211310</td>\n",
       "      <td>0.035964</td>\n",
       "      <td>0.058267</td>\n",
       "      <td>0.976103</td>\n",
       "      <td>0.003496</td>\n",
       "      <td>0.559029</td>\n",
       "      <td>0.381819</td>\n",
       "      <td>0.089357</td>\n",
       "      <td>0.064752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.375806</td>\n",
       "      <td>0.137629</td>\n",
       "      <td>0.264998</td>\n",
       "      <td>0.177378</td>\n",
       "      <td>0.009751</td>\n",
       "      <td>0.015562</td>\n",
       "      <td>0.008744</td>\n",
       "      <td>0.008264</td>\n",
       "      <td>0.018324</td>\n",
       "      <td>0.019838</td>\n",
       "      <td>...</td>\n",
       "      <td>0.149487</td>\n",
       "      <td>0.197698</td>\n",
       "      <td>0.009928</td>\n",
       "      <td>0.014079</td>\n",
       "      <td>0.944857</td>\n",
       "      <td>0.005313</td>\n",
       "      <td>0.615985</td>\n",
       "      <td>0.743413</td>\n",
       "      <td>0.143422</td>\n",
       "      <td>0.077947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.357351</td>\n",
       "      <td>0.188850</td>\n",
       "      <td>0.614028</td>\n",
       "      <td>0.584217</td>\n",
       "      <td>0.026347</td>\n",
       "      <td>0.041739</td>\n",
       "      <td>0.013478</td>\n",
       "      <td>0.015932</td>\n",
       "      <td>0.039720</td>\n",
       "      <td>0.039329</td>\n",
       "      <td>...</td>\n",
       "      <td>0.060249</td>\n",
       "      <td>0.101572</td>\n",
       "      <td>0.066991</td>\n",
       "      <td>0.130748</td>\n",
       "      <td>0.765239</td>\n",
       "      <td>0.835360</td>\n",
       "      <td>0.709012</td>\n",
       "      <td>0.475913</td>\n",
       "      <td>0.589092</td>\n",
       "      <td>0.705933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>960</th>\n",
       "      <td>0.460974</td>\n",
       "      <td>0.373973</td>\n",
       "      <td>0.527525</td>\n",
       "      <td>0.348726</td>\n",
       "      <td>0.012121</td>\n",
       "      <td>0.018362</td>\n",
       "      <td>0.013141</td>\n",
       "      <td>0.012451</td>\n",
       "      <td>0.020573</td>\n",
       "      <td>0.019234</td>\n",
       "      <td>...</td>\n",
       "      <td>0.103321</td>\n",
       "      <td>0.182883</td>\n",
       "      <td>0.025239</td>\n",
       "      <td>0.016320</td>\n",
       "      <td>0.814373</td>\n",
       "      <td>0.253355</td>\n",
       "      <td>0.748788</td>\n",
       "      <td>0.440532</td>\n",
       "      <td>0.175363</td>\n",
       "      <td>0.120263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>961</th>\n",
       "      <td>0.352716</td>\n",
       "      <td>0.003427</td>\n",
       "      <td>0.161315</td>\n",
       "      <td>0.010795</td>\n",
       "      <td>0.012184</td>\n",
       "      <td>0.014054</td>\n",
       "      <td>0.011086</td>\n",
       "      <td>0.015633</td>\n",
       "      <td>0.016119</td>\n",
       "      <td>0.020180</td>\n",
       "      <td>...</td>\n",
       "      <td>0.040901</td>\n",
       "      <td>0.039028</td>\n",
       "      <td>0.016575</td>\n",
       "      <td>0.023179</td>\n",
       "      <td>0.865881</td>\n",
       "      <td>0.121413</td>\n",
       "      <td>0.375970</td>\n",
       "      <td>0.031627</td>\n",
       "      <td>0.145090</td>\n",
       "      <td>0.012543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>962</th>\n",
       "      <td>0.396262</td>\n",
       "      <td>0.101765</td>\n",
       "      <td>0.150565</td>\n",
       "      <td>0.042608</td>\n",
       "      <td>0.104519</td>\n",
       "      <td>0.165757</td>\n",
       "      <td>0.052669</td>\n",
       "      <td>0.037540</td>\n",
       "      <td>0.158977</td>\n",
       "      <td>0.158696</td>\n",
       "      <td>...</td>\n",
       "      <td>0.272364</td>\n",
       "      <td>0.324432</td>\n",
       "      <td>0.116948</td>\n",
       "      <td>0.098149</td>\n",
       "      <td>0.977993</td>\n",
       "      <td>0.004935</td>\n",
       "      <td>0.616752</td>\n",
       "      <td>0.565716</td>\n",
       "      <td>0.399598</td>\n",
       "      <td>0.133447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>963</th>\n",
       "      <td>0.325693</td>\n",
       "      <td>0.048607</td>\n",
       "      <td>0.161042</td>\n",
       "      <td>0.052766</td>\n",
       "      <td>0.004566</td>\n",
       "      <td>0.003033</td>\n",
       "      <td>0.004284</td>\n",
       "      <td>0.004835</td>\n",
       "      <td>0.003868</td>\n",
       "      <td>0.006606</td>\n",
       "      <td>...</td>\n",
       "      <td>0.279905</td>\n",
       "      <td>0.294204</td>\n",
       "      <td>0.005643</td>\n",
       "      <td>0.010843</td>\n",
       "      <td>0.979402</td>\n",
       "      <td>0.008850</td>\n",
       "      <td>0.522074</td>\n",
       "      <td>0.565589</td>\n",
       "      <td>0.037580</td>\n",
       "      <td>0.032726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>964</th>\n",
       "      <td>0.462384</td>\n",
       "      <td>0.598191</td>\n",
       "      <td>0.910849</td>\n",
       "      <td>0.205630</td>\n",
       "      <td>0.020418</td>\n",
       "      <td>0.026529</td>\n",
       "      <td>0.018448</td>\n",
       "      <td>0.009828</td>\n",
       "      <td>0.030428</td>\n",
       "      <td>0.029405</td>\n",
       "      <td>...</td>\n",
       "      <td>0.145012</td>\n",
       "      <td>0.180061</td>\n",
       "      <td>0.124835</td>\n",
       "      <td>0.147032</td>\n",
       "      <td>0.928279</td>\n",
       "      <td>0.002896</td>\n",
       "      <td>0.916477</td>\n",
       "      <td>0.515998</td>\n",
       "      <td>0.481413</td>\n",
       "      <td>0.228993</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>965 rows Ã— 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     CO2168.mean  CO2168.std  H2O168.mean  H2O168.std  NO168.std  NO336.std  \\\n",
       "0       0.278938    0.018998     0.183163    0.022930   0.009311   0.012234   \n",
       "1       0.504000    0.015784     0.022105    0.007552   0.193844   0.278596   \n",
       "2       0.257581    0.050786     0.193513    0.136942   0.020796   0.030065   \n",
       "3       0.375806    0.137629     0.264998    0.177378   0.009751   0.015562   \n",
       "4       0.357351    0.188850     0.614028    0.584217   0.026347   0.041739   \n",
       "..           ...         ...          ...         ...        ...        ...   \n",
       "960     0.460974    0.373973     0.527525    0.348726   0.012121   0.018362   \n",
       "961     0.352716    0.003427     0.161315    0.010795   0.012184   0.014054   \n",
       "962     0.396262    0.101765     0.150565    0.042608   0.104519   0.165757   \n",
       "963     0.325693    0.048607     0.161042    0.052766   0.004566   0.003033   \n",
       "964     0.462384    0.598191     0.910849    0.205630   0.020418   0.026529   \n",
       "\n",
       "     NO42.std  NO504.mean  NO504.std  NO672.std  ...  RPAR.mean  RPAR.std  \\\n",
       "0    0.085353    0.011402   0.017434   0.011019  ...   0.018861  0.028178   \n",
       "1    0.125013    0.121995   0.281247   0.279674  ...   0.190066  0.239194   \n",
       "2    0.009843    0.010364   0.025180   0.028995  ...   0.159068  0.211310   \n",
       "3    0.008744    0.008264   0.018324   0.019838  ...   0.149487  0.197698   \n",
       "4    0.013478    0.015932   0.039720   0.039329  ...   0.060249  0.101572   \n",
       "..        ...         ...        ...        ...  ...        ...       ...   \n",
       "960  0.013141    0.012451   0.020573   0.019234  ...   0.103321  0.182883   \n",
       "961  0.011086    0.015633   0.016119   0.020180  ...   0.040901  0.039028   \n",
       "962  0.052669    0.037540   0.158977   0.158696  ...   0.272364  0.324432   \n",
       "963  0.004284    0.004835   0.003868   0.006606  ...   0.279905  0.294204   \n",
       "964  0.018448    0.009828   0.030428   0.029405  ...   0.145012  0.180061   \n",
       "\n",
       "     SO2168.mean  SO2168.std  SWS.mean   SWS.std  T84.mean   T84.std  \\\n",
       "0       0.022406    0.015538  0.963095  0.003594  0.426378  0.028074   \n",
       "1       0.194391    0.035191  0.941012  0.010179  0.129581  0.087790   \n",
       "2       0.035964    0.058267  0.976103  0.003496  0.559029  0.381819   \n",
       "3       0.009928    0.014079  0.944857  0.005313  0.615985  0.743413   \n",
       "4       0.066991    0.130748  0.765239  0.835360  0.709012  0.475913   \n",
       "..           ...         ...       ...       ...       ...       ...   \n",
       "960     0.025239    0.016320  0.814373  0.253355  0.748788  0.440532   \n",
       "961     0.016575    0.023179  0.865881  0.121413  0.375970  0.031627   \n",
       "962     0.116948    0.098149  0.977993  0.004935  0.616752  0.565716   \n",
       "963     0.005643    0.010843  0.979402  0.008850  0.522074  0.565589   \n",
       "964     0.124835    0.147032  0.928279  0.002896  0.916477  0.515998   \n",
       "\n",
       "      CS.mean    CS.std  \n",
       "0    0.025721  0.015359  \n",
       "1    0.222128  0.014814  \n",
       "2    0.089357  0.064752  \n",
       "3    0.143422  0.077947  \n",
       "4    0.589092  0.705933  \n",
       "..        ...       ...  \n",
       "960  0.175363  0.120263  \n",
       "961  0.145090  0.012543  \n",
       "962  0.399598  0.133447  \n",
       "963  0.037580  0.032726  \n",
       "964  0.481413  0.228993  \n",
       "\n",
       "[965 rows x 38 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_hidden = pd.read_csv(\"data/npf_test_hidden.csv\")\n",
    "X_hidden = X_hidden[X_hidden.columns.intersection(X.columns)]\n",
    "X_hidden_norm = (X_hidden - X_hidden.min())/(X_hidden.max()-X_hidden.min())\n",
    "X_hidden_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_4_pred = eclf_4.predict(X_hidden_norm)\n",
    "y_2_pred = eclf_2.predict(X_hidden_norm)\n",
    "y_2_pred_prob = eclf_2.predict_proba(X_hidden_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = pd.DataFrame({'class4':y_4_pred,'p':y_2_pred_prob[:,0]},)\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "score = cross_val_score(eclf_2,X_norm,y2,cv=10,n_jobs=-1,scoring='accuracy').mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = answer.T\n",
    "answer.reset_index(inplace=True)\n",
    "answer = answer.T\n",
    "answer.columns = [score,\"\"]\n",
    "answer.to_csv('answer/answers.csv',index =False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5053848f1e1ce6d9c67b4d0af35009a6322e9959d1af6f676e18003e4a846f54"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
